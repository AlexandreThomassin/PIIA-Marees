{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a937e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics.quantile import QuantileLoss\n",
    "import pytorch_forecasting.metrics\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55770cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = open(\"2016_2022.csv\", \"a\")\n",
    "csv_file.write(\"\\n\")\n",
    "csv_file.write(\"\")\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec85022e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Valeur  Source    Time\n",
      "1         3.607       3       0\n",
      "13        3.496       3       1\n",
      "25        3.446       3       2\n",
      "37        3.298       3       3\n",
      "49        3.229       3       4\n",
      "...         ...     ...     ...\n",
      "4034625   1.931       3  338248\n",
      "4034637   1.915       3  338249\n",
      "4034649   1.918       3  338250\n",
      "4034661   1.942       3  338251\n",
      "4034673   1.998       3  338252\n",
      "\n",
      "[338253 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "datas = pd.read_csv(\"2016_2022.csv\")\n",
    "data = datas[datas[\"Source\"] == 3]\n",
    "n = len(data)\n",
    "time_idx = [i for i in range(n)]\n",
    "data.insert(3, \"Time\", time_idx, True)\n",
    "data = data.drop(\"Date\", axis = 1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268b0e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "max_encoder_length = 50\n",
    "max_prediction_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0012593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338242\n",
      "TimeSeriesDataSet[length=338184](\n",
      "\ttime_idx='Time',\n",
      "\ttarget='Valeur',\n",
      "\tgroup_ids=['Source'],\n",
      "\tweight=None,\n",
      "\tmax_encoder_length=50,\n",
      "\tmin_encoder_length=50,\n",
      "\tmin_prediction_idx=0,\n",
      "\tmin_prediction_length=10,\n",
      "\tmax_prediction_length=10,\n",
      "\tstatic_categoricals=[],\n",
      "\tstatic_reals=['Source'],\n",
      "\ttime_varying_known_categoricals=[],\n",
      "\ttime_varying_known_reals=['Time'],\n",
      "\ttime_varying_unknown_categoricals=[],\n",
      "\ttime_varying_unknown_reals=['Valeur'],\n",
      "\tvariable_groups={},\n",
      "\tconstant_fill_strategy={},\n",
      "\tallow_missing_timesteps=False,\n",
      "\tlags={},\n",
      "\tadd_relative_time_idx=False,\n",
      "\tadd_target_scales=False,\n",
      "\tadd_encoder_length=False,\n",
      "\ttarget_normalizer=EncoderNormalizer(\n",
      "\tmethod='standard',\n",
      "\tcenter=True,\n",
      "\tmax_length=None,\n",
      "\ttransformation='relu',\n",
      "\tmethod_kwargs={}\n",
      "),\n",
      "\tcategorical_encoders={'__group_id__Source': NaNLabelEncoder(add_nan=False, warn=True)},\n",
      "\tscalers={'Source': StandardScaler(), 'Time': StandardScaler()},\n",
      "\trandomize_length=None,\n",
      "\tpredict_mode=False\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "training_cutoff = data[\"Time\"].max() - max_prediction_length\n",
    "print(training_cutoff)\n",
    "#print(data[lambda x: x.Time <= training_cutoff])\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.Time <= training_cutoff],\n",
    "    time_idx= \"Time\",\n",
    "    target= \"Valeur\",\n",
    "    group_ids=[\"Source\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_reals=[\"Source\"],\n",
    "    time_varying_known_reals=[\"Time\"],\n",
    "    time_varying_unknown_reals=[\"Valeur\"],\n",
    ")\n",
    "print(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e69495a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesDataSet[length=60](\n",
      "\ttime_idx='Time',\n",
      "\ttarget='Valeur',\n",
      "\tgroup_ids=['Source'],\n",
      "\tweight=None,\n",
      "\tmax_encoder_length=50,\n",
      "\tmin_encoder_length=50,\n",
      "\tmin_prediction_idx=338184,\n",
      "\tmin_prediction_length=10,\n",
      "\tmax_prediction_length=10,\n",
      "\tstatic_categoricals=[],\n",
      "\tstatic_reals=['Source'],\n",
      "\ttime_varying_known_categoricals=[],\n",
      "\ttime_varying_known_reals=['Time'],\n",
      "\ttime_varying_unknown_categoricals=[],\n",
      "\ttime_varying_unknown_reals=['Valeur'],\n",
      "\tvariable_groups={},\n",
      "\tconstant_fill_strategy={},\n",
      "\tallow_missing_timesteps=False,\n",
      "\tlags={},\n",
      "\tadd_relative_time_idx=False,\n",
      "\tadd_target_scales=False,\n",
      "\tadd_encoder_length=False,\n",
      "\ttarget_normalizer=EncoderNormalizer(\n",
      "\tmethod='standard',\n",
      "\tcenter=True,\n",
      "\tmax_length=None,\n",
      "\ttransformation='relu',\n",
      "\tmethod_kwargs={}\n",
      "),\n",
      "\tcategorical_encoders={'__group_id__Source': NaNLabelEncoder(add_nan=False, warn=True)},\n",
      "\tscalers={'Source': StandardScaler(), 'Time': StandardScaler()},\n",
      "\trandomize_length=None,\n",
      "\tpredict_mode=False\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create validation and training dataset\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, min_prediction_idx=training.index.time.max() + 1, stop_randomization=True)\n",
    "batch_size = 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=8)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=8)\n",
    "print(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0701700a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/alex/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:175: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "# define trainer with early stopping\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=1, verbose=1, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    gradient_clip_val=0.1,\n",
    "    #limit_train_batches=50,\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b045fadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 62.0k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniconda3/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "/home/alex/miniconda3/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=32,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=16,\n",
    "    output_size=7,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=1,\n",
    "    reduce_on_plateau_patience=4\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c019525",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, idx = batch\n",
    "        pred = self(X)\n",
    "        val_loss = ACARMSELoss()(pred, y)\n",
    "\n",
    "        self.log('val_loss', val_loss)\n",
    "        return {\"val_loss\": val_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545d429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9979152493c4186a004e30b2093ae0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Restoring states from the checkpoint path at /mnt/c/Users/alex4/Desktop/COURS/PIIA-Marees/PyTorch/.lr_find_4cb64ba6-2cc0-4de2-8f4b-3aaf566ee209.ckpt\n"
     ]
    }
   ],
   "source": [
    "# find optimal learning rate (set limit_train_batches to 1.0 and log_interval = -1)\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader, early_stop_threshold=1000.0, max_lr=0.3,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da482326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 0     \n",
      "3  | prescalers                         | ModuleDict                      | 96    \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 1.8 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 3.8 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.8 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K \n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K \n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K \n",
      "20 | output_layer                       | Linear                          | 231   \n",
      "----------------------------------------------------------------------------------------\n",
      "62.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "62.0 K    Total params\n",
      "0.248     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fdae01bdde4d2fa56ea7f68d977979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit the model\n",
    "trainer.fit(\n",
    "    tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb867377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
